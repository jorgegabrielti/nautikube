# Perguntas Frequentes (FAQ)

## Quest√µes Gerais

### O que √© o Mekhanikube?

Mekhanikube √© uma solu√ß√£o containerizada que combina K8sGPT e Ollama para fornecer an√°lise alimentada por IA de clusters Kubernetes. Ele identifica problemas, explica suas causas e sugere solu√ß√µes usando modelos LLM locais.

### Por que "Mekhanikube"?

**Mekhani** (Grego: ŒºŒ∑œáŒ±ŒΩŒπŒ∫œåœÇ) = mec√¢nico + **kube** (Kubernetes) = Seu mec√¢nico Kubernetes!

### √â gratuito?

Sim! Mekhanikube √© c√≥digo aberto sob a Licen√ßa MIT. Todos os componentes (K8sGPT, Ollama) tamb√©m s√£o gratuitos e de c√≥digo aberto.

### Ele envia meus dados para algum lugar?

N√£o! Tudo roda localmente na sua m√°quina. Os dados do seu cluster nunca saem da sua infraestrutura. Sem telemetria, sem chamadas de API externas.

---

## Instala√ß√£o & Configura√ß√£o

### Quais s√£o os requisitos do sistema?

**M√≠nimo**:
- Docker & Docker Compose
- 2 n√∫cleos de CPU
- 4GB RAM
- 10GB de espa√ßo em disco
- Cluster Kubernetes ativo

**Recomendado**:
- 4+ n√∫cleos de CPU
- 8GB+ RAM
- 20GB+ de espa√ßo em disco

### Quais sistemas operacionais s√£o suportados?

- ‚úÖ Windows 10/11 (com Docker Desktop)
- ‚úÖ macOS (Intel & Apple Silicon)
- ‚úÖ Linux (qualquer distribui√ß√£o com Docker)

### Posso usar com qualquer cluster Kubernetes?

Sim! Mekhanikube funciona com:
- Clusters locais (Docker Desktop, Minikube, Kind)
- Clusters na nuvem (EKS, GKE, AKS)
- Clusters on-premise
- Qualquer cluster acess√≠vel via kubeconfig

### Quanto tempo leva a configura√ß√£o?

- Primeira vez: ~15-20 minutos (incluindo download do modelo)
- Inicializa√ß√µes subsequentes: ~30 segundos
- Mudan√ßas de modelo: ~5-10 minutos por modelo

---

## Quest√µes de Uso

### Qual modelo de IA devo usar?

| Modelo | Melhor Para | Velocidade | Qualidade | Portugu√™s | Tamanho |
|--------|-------------|------------|-----------|-----------|---------|
| **llama3.1:8b** ‚≠ê | **Recomendado (PT-BR)** | Boa | Excelente | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 4.7GB |
| **gemma2:9b** | Melhor qualidade | M√©dia | Excelente | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 5.4GB |
| **qwen2.5:7b** | Velocidade | R√°pida | Muito Boa | ‚≠ê‚≠ê‚≠ê‚≠ê | 4.7GB |
| **mistral** | Uso geral | M√©dia | Boa | ‚≠ê‚≠ê‚≠ê | 4.1GB |
| **tinyllama** | Varreduras r√°pidas | Muito R√°pida | B√°sica | ‚≠ê‚≠ê | 1.1GB |

Comece com `llama3.1:8b` - oferece excelente suporte ao portugu√™s brasileiro.

### Posso usar m√∫ltiplos modelos?

Sim! Instale m√∫ltiplos modelos e alterne entre eles:

```bash
# Instalar modelos adicionais
docker exec mekhanikube-ollama ollama pull mistral
docker exec mekhanikube-ollama ollama pull tinyllama

# Trocar modelo ativo
docker exec mekhanikube-ollama ollama run mistral
```

### Com que frequ√™ncia devo executar a an√°lise?

**Cronograma recomendado**:
- **Ap√≥s deployments**: Verificar problemas imediatamente
- **Diariamente**: Verifica√ß√µes rotineiras de sa√∫de
- **Antes de releases**: Validar estado do cluster
- **Quando alertas disparam**: Investigar causa raiz

### Posso analisar apenas recursos espec√≠ficos?

Sim! Use filtros:

```bash
# Analisar apenas Pods
docker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Pod --explain

# Analisar apenas Services
docker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Service --explain

# Listar todos os filtros
docker exec mekhanikube-k8sgpt k8sgpt filters list
```

Ou namespaces espec√≠ficos:

```bash
docker exec mekhanikube-k8sgpt k8sgpt analyze --namespace production --explain
```

### Que tipos de problemas ele pode detectar?

K8sGPT analisa:
- **Pods**: CrashLoopBackOff, ImagePullBackOff, OOMKilled
- **Services**: Problemas de endpoint, incompatibilidades de seletor
- **Deployments**: Problemas de r√©plica, problemas de atualiza√ß√£o
- **PVCs**: Falhas de vincula√ß√£o, problemas de armazenamento
- **Ingress**: Erros de configura√ß√£o
- **StatefulSets**: Problemas de ordena√ß√£o
- **HPA**: Problemas de escalonamento
- E mais!

---

## Quest√µes T√©cnicas

### Como funciona?

1. K8sGPT escaneia seu cluster Kubernetes via API Kubernetes
2. Analisadores integrados identificam problemas (ex: pod n√£o iniciando)
3. K8sGPT envia o contexto do problema para o Ollama
4. O LLM do Ollama gera uma explica√ß√£o leg√≠vel para humanos
5. Resultados s√£o exibidos com descri√ß√£o do problema, explica√ß√£o da IA e corre√ß√µes sugeridas

### Ele modifica meu cluster?

**N√£o!** Mekhanikube √© somente leitura. Ele:
- ‚úÖ L√™ o estado do cluster
- ‚úÖ Analisa configura√ß√µes
- ‚úÖ Gera relat√≥rios
- ‚ùå Nunca faz mudan√ßas
- ‚ùå Nunca deleta recursos
- ‚ùå Nunca aplica configura√ß√µes

### Quais permiss√µes ele precisa?

K8sGPT requer acesso **somente leitura** aos recursos do cluster. As mesmas permiss√µes dos comandos `kubectl get`.

### Posso executar em CI/CD?

Sim! Exemplo:

```yaml
# GitLab CI
k8s-analysis:
  script:
    - docker-compose up -d
    - docker exec mekhanikube-k8sgpt k8sgpt analyze --explain > report.txt
  artifacts:
    paths:
      - report.txt
```

### Posso exportar resultados?

Sim, use as op√ß√µes de sa√≠da do K8sGPT:

```bash
# Formato JSON
docker exec mekhanikube-k8sgpt k8sgpt analyze --explain --output json

# Salvar em arquivo
docker exec mekhanikube-k8sgpt k8sgpt analyze --explain > analysis.txt
```

---

## Solu√ß√£o de Problemas

### Por que est√° lento?

**Poss√≠veis causas**:
1. **Modelo grande**: Tente `tinyllama` para respostas mais r√°pidas
2. **Muitos recursos**: Use filtros ou escopo de namespace
3. **RAM limitada**: Aloque mais mem√≥ria para o Docker
4. **Gargalo de CPU**: Feche outras aplica√ß√µes

**Otimiza√ß√£o**:
```bash
# Usar modelo menor
docker exec mekhanikube-ollama ollama pull tinyllama

# Limitar escopo
docker exec mekhanikube-k8sgpt k8sgpt analyze --namespace default --explain
docker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Pod --explain
```

### Diz "nenhum problema encontrado" mas sei que h√° problemas

1. **Verificar namespace**: Padr√£o √© todos os namespaces
   ```bash
   docker exec mekhanikube-k8sgpt k8sgpt analyze --namespace seu-namespace --explain
   ```

2. **Tentar filtros diferentes**: Alguns problemas precisam de analisadores espec√≠ficos
   ```bash
   docker exec mekhanikube-k8sgpt k8sgpt filters list
   docker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Pod --explain
   ```

3. **Verificar acesso ao cluster**:
   ```bash
   docker exec mekhanikube-k8sgpt kubectl get pods --all-namespaces
   ```

### Ollama continua baixando modelos

Modelos s√£o armazenados em volumes Docker. Se voc√™ executar `docker-compose down -v`, modelos s√£o deletados.

**Preservar modelos**:
```bash
# Parar sem remover volumes
docker-compose down

# Ou apenas reiniciar
docker-compose restart
```

### Posso usar uma inst√¢ncia Ollama externa?

Sim! Modifique o `docker-compose.yml`:

```yaml
k8sgpt:
  environment:
    - OLLAMA_BASEURL=http://seu-servidor-ollama:11434
```

Ent√£o remova a defini√ß√£o do servi√ßo Ollama.

---

## Uso Avan√ßado

### Posso personalizar os analisadores do K8sGPT?

K8sGPT usa analisadores integrados. Para habilitar/desabilitar:

```bash
# Listar filtros dispon√≠veis
docker exec mekhanikube-k8sgpt k8sgpt filters list

# Usar filtros espec√≠ficos
docker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Pod,Service --explain
```

### Posso usar um backend LLM diferente?

Sim! K8sGPT suporta:
- Ollama (local) - padr√£o
- OpenAI (nuvem)
- Azure OpenAI (nuvem)
- LocalAI (alternativa local)

Exemplo para OpenAI:
```bash
docker exec mekhanikube-k8sgpt k8sgpt auth add \
  --backend openai \
  --model gpt-4 \
  --password SUA_API_KEY
```

### Como fa√ßo backup da minha configura√ß√£o?

```bash
# Backup dos modelos Ollama
docker run --rm \
  -v mekhanikube-ollama-data:/data \
  -v ${PWD}:/backup \
  alpine tar czf /backup/ollama-backup.tar.gz /data

# Backup da config K8sGPT
docker run --rm \
  -v mekhanikube-k8sgpt-config:/data \
  -v ${PWD}:/backup \
  alpine tar czf /backup/k8sgpt-backup.tar.gz /data
```

### Posso executar m√∫ltiplas inst√¢ncias?

Sim, mas altere os nomes dos cont√™ineres para evitar conflitos:

```bash
# No arquivo .env
CONTAINER_NAME_OLLAMA=mekhanikube-ollama-2
CONTAINER_NAME_K8SGPT=mekhanikube-k8sgpt-2
OLLAMA_PORT=11435
```

### Como atualizo para a vers√£o mais recente?

```bash
# Puxar c√≥digo mais recente
git pull origin main

# Reconstruir cont√™ineres
docker-compose build

# Reiniciar servi√ßos
docker-compose restart
```

---

## Performance & Otimiza√ß√£o

### Quanto espa√ßo em disco preciso?

- **Instala√ß√£o base**: ~500MB (cont√™ineres)
- **Por modelo**: 1-10GB dependendo do modelo
- **Logs**: ~100MB (cresce com o tempo)
- **Recomenda√ß√£o**: 20GB de espa√ßo livre

### Posso limitar o uso de recursos?

Sim! Edite o `docker-compose.yml`:

```yaml
services:
  ollama:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
```

### Qual modelo √© mais r√°pido?

Ranking de velocidade (mais r√°pido para mais lento):
1. `tinyllama` - ~2-5 segundos por explica√ß√£o
2. `gemma:7b` - ~5-10 segundos por explica√ß√£o
3. `mistral` - ~8-15 segundos por explica√ß√£o
4. `llama2:13b` - ~15-30 segundos por explica√ß√£o

### Posso usar acelera√ß√£o GPU?

Sim, se voc√™ tiver GPU NVIDIA:

1. Instale o [NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-docker)
2. Modifique o `docker-compose.yml`:

```yaml
services:
  ollama:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## Seguran√ßa & Privacidade

### Meu kubeconfig est√° seguro?

Sim:
- Montado como **somente leitura** no cont√™iner
- Nunca modificado ou exposto
- Usado apenas para acesso √† API
- Cont√™iner est√° isolado

### Quais dados s√£o coletados?

**Nenhum!** Mekhanikube:
- ‚ùå Sem telemetria
- ‚ùå Sem analytics
- ‚ùå Sem conex√µes externas (exceto downloads de modelos)
- ‚ùå Sem compartilhamento de dados

### Posso usar em produ√ß√£o?

Sim, mas:
- ‚úÖ √â somente leitura (seguro)
- ‚úÖ Sem modifica√ß√µes no cluster
- ‚ö†Ô∏è Garanta recursos adequados
- ‚ö†Ô∏è Teste em dev/staging primeiro
- ‚ö†Ô∏è Monitore o uso de recursos

### Devo fazer commit do meu arquivo .env?

**N√ÉO!** O arquivo `.env` pode conter informa√ß√µes sens√≠veis. J√° est√° no `.gitignore`.

---

## Contribuindo & Suporte

### Como posso contribuir?

Veja [CONTRIBUTING.md](../CONTRIBUTING.md) para:
- Reportar bugs
- Sugerir funcionalidades
- Enviar pull requests
- Melhorar a documenta√ß√£o

### Onde reporto bugs?

Abra uma issue no [GitHub Issues](https://github.com/jorgegabrielti/mekhanikube/issues) com:
- SO e vers√£o do Docker
- Sa√≠da de `docker-compose ps`
- Passos para reproduzir
- Mensagens de erro/logs

### Posso solicitar novas funcionalidades?

Sim! Abra uma GitHub Issue com:
- Descri√ß√£o da funcionalidade
- Caso de uso
- Comportamento esperado
- Exemplo de uso

### Como obtenho ajuda?

1. Verifique este FAQ
2. Leia [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
3. Pesquise [issues existentes](https://github.com/jorgegabrielti/mekhanikube/issues)
4. Abra uma nova issue
5. Participe das discuss√µes

---

## Roadmap & Futuro

### O que est√° planejado para vers√µes futuras?

- Dashboard Web UI
- Integra√ß√µes Slack/Teams
- Plugins de analisador customizados
- Rastreamento de an√°lise hist√≥rica
- Modo operador Kubernetes
- Suporte multi-cluster

### Posso patrocinar o projeto?

Ainda n√£o, mas fique ligado! Enquanto isso, contribui√ß√µes e estrelas no GitHub s√£o apreciadas! ‚≠ê

---

## Compara√ß√£o com Outras Ferramentas

### Mekhanikube vs kubectl

- **kubectl**: Comandos de baixo n√≠vel, interpreta√ß√£o manual
- **Mekhanikube**: An√°lise automatizada com explica√ß√µes de IA

### Mekhanikube vs K9s

- **K9s**: TUI interativa para gerenciamento de cluster
- **Mekhanikube**: Detec√ß√£o automatizada de problemas com IA

### Mekhanikube vs Lens

- **Lens**: IDE desktop GUI para Kubernetes
- **Mekhanikube**: Ferramenta CLI com an√°lise de IA

### Mekhanikube vs Prometheus/Grafana

- **Prometheus/Grafana**: M√©tricas e monitoramento
- **Mekhanikube**: Detec√ß√£o e explica√ß√£o de problemas

**Eles se complementam!** Use Mekhanikube para diagn√≥sticos junto com suas ferramentas existentes.

---

## Recursos Adicionais

- üìñ [Documenta√ß√£o de Arquitetura](ARCHITECTURE.md)
- üîß [Guia de Solu√ß√£o de Problemas](TROUBLESHOOTING.md)
- ü§ù [Diretrizes de Contribui√ß√£o](../CONTRIBUTING.md)
- üìù [Hist√≥rico de Mudan√ßas](../CHANGELOG.md)
- üêô [Reposit√≥rio GitHub](https://github.com/jorgegabrielti/mekhanikube)
- üîó [Documenta√ß√£o K8sGPT](https://docs.k8sgpt.ai/)
- ü¶ô [Documenta√ß√£o Ollama](https://github.com/ollama/ollama)

---

**N√£o encontrou sua resposta?** Abra uma issue no GitHub!
