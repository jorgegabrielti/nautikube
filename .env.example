# Environment Configuration for Mekhanikube v2.0

# ============================================
# Ollama Configuration
# ============================================
# Default AI model to use for Mekhanikube v2
# Recommended: llama3.1:8b (best Portuguese support)
# Options: llama3.1:8b, gemma2:9b, qwen2.5:7b, mistral, tinyllama
OLLAMA_MODEL=llama3.1:8b

# Ollama API port
OLLAMA_PORT=11434

# Ollama host (used internally by containers)
OLLAMA_HOST=http://host.docker.internal:11434

# ============================================
# Mekhanikube v2 Configuration
# ============================================
# Default namespace to analyze (leave empty for all namespaces)
MEKHANIKUBE_DEFAULT_NAMESPACE=

# Default language for AI explanations (Portuguese, English)
MEKHANIKUBE_DEFAULT_LANGUAGE=Portuguese

# Enable explanations by default (true/false)
MEKHANIKUBE_EXPLAIN=true

# Default filter (Pod, ConfigMap, or empty for all)
MEKHANIKUBE_DEFAULT_FILTER=

# ============================================
# K8sGPT Configuration (Legacy Mode)
# ============================================
# Only used when running with --profile k8sgpt

# Default namespace
K8SGPT_DEFAULT_NAMESPACE=

# Backend type
K8SGPT_BACKEND=ollama

# Enable explanations
K8SGPT_EXPLAIN=true

# ============================================
# Kubernetes Configuration
# ============================================
# Path to kubeconfig file
# Windows: C:/Users/${USERNAME}/.kube/config
# Linux/Mac: ~/.kube/config
KUBECONFIG_PATH=~/.kube/config

# ============================================
# Docker Configuration
# ============================================
# Container names (change if you have conflicts)
CONTAINER_NAME_OLLAMA=mekhanikube-ollama
CONTAINER_NAME_MEKHANIKUBE=mekhanikube
CONTAINER_NAME_K8SGPT=mekhanikube-k8sgpt

# Docker network mode (host recommended for K8s access)
NETWORK_MODE=host

# ============================================
# Development Configuration
# ============================================
# Enable debug logging (true/false)
DEBUG=false

# Go build tags (for development)
# GO_BUILD_TAGS=

# ============================================
# Resource Limits (optional)
# ============================================
# Ollama memory limit (e.g., 4g, 8g)
# OLLAMA_MEMORY_LIMIT=8g

# K8sGPT memory limit (e.g., 512m, 1g)
# K8SGPT_MEMORY_LIMIT=512m

# ============================================
# Advanced Settings
# ============================================
# Log level (debug, info, warn, error)
LOG_LEVEL=info

# Enable verbose output (true/false)
VERBOSE=false

# Restart policy (unless-stopped, always, no)
RESTART_POLICY=unless-stopped

# ============================================
# Development Settings
# ============================================
# Build K8sGPT from specific branch
# K8SGPT_BRANCH=main

# Use specific Ollama version
# OLLAMA_VERSION=latest

# ============================================
# Notes
# ============================================
# 1. Copy this file to .env and modify values as needed
# 2. Never commit .env file (it may contain sensitive data)
# 3. Most settings have sensible defaults and don't need to be changed
# 4. After changing .env, restart services: docker-compose down && docker-compose up -d
